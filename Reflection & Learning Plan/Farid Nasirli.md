# Reflection
This project provided a valuable opportunity to apply and expand my understanding of parallel programming within the context of embedded systems and AI inferencing. One of the most important takeaways was learning how to configure and utilize a GPU-accelerated embedded platform, specifically the NVIDIA Jetson Orin Nano, to perform real-time computer vision tasks. I became familiar with several new tools and frameworks, such as PyTorch for deep learning, OpenCV for image processing, jtop for GPU monitoring, and various NVIDIA-specific utilities like nvgstcapture and JetPack SDK. These tools were previously unfamiliar to me, and gaining hands-on experience with them significantly broadened my technical capabilities. I also improved my ability to write modular Python scripts that are optimized for real-time performance and hardware compatibility. This will be especially beneficial for future work in robotics, embedded AI, or real-time control systems, where performance and reliability are critical.

Several aspects of the project went smoothly, including the initial setup and configuration of the Jetson device, the installation of dependencies, and the integration of the camera for live feed acquisition. The decision to work iteratively, testing each component separately before integration, was crucial in avoiding cascading errors and allowed us to isolate problems more easily. For example, we verified camera compatibility using both OpenCV and NVIDIAâ€™s native capture tool before beginning inference work, which saved time later on. My primary individual contribution involved setting up the environment, writing the image acquisition and blur filter scripts, and testing YOLOv5 performance on the GPU. These tasks required careful attention to software compatibility and system resource management, which I handled by regularly checking device utilization and tweaking package versions as needed.

Despite the successes, we faced challenges that included GPU compatibility issues, installation errors with PyTorch wheels for Jetson, and runtime errors due to mismatched Python versions and CUDA dependencies. Debugging these problems required a deep dive into documentation and forum discussions, and at times trial-and-error. I was also responsible for resolving camera indexing issues and modifying the detection code to work with our specific video device. Overall, the project strengthened my problem-solving skills, particularly in diagnosing hardware-software interaction problems on embedded Linux systems.
