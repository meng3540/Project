# Reflection
This project provided a valuable opportunity to apply and expand my understanding of parallel programming within the context of embedded systems and AI inferencing. One of the most important takeaways was learning how to configure and utilize a GPU-accelerated embedded platform, specifically the NVIDIA Jetson Orin Nano, to perform real-time computer vision tasks. I became familiar with several new tools and frameworks, such as PyTorch for deep learning, OpenCV for image processing, jtop for GPU monitoring, and various NVIDIA-specific utilities like nvgstcapture and JetPack SDK. These tools were previously unfamiliar to me, and gaining hands-on experience with them significantly broadened my technical capabilities. I also improved my ability to write modular Python scripts that are optimized for real-time performance and hardware compatibility. This will be especially beneficial for future work in robotics, embedded AI, or real-time control systems, where performance and reliability are critical.

Several aspects of the project went smoothly, including the initial setup and configuration of the Jetson device, the installation of dependencies, and the integration of the camera for live feed acquisition. The decision to work iteratively, testing each component separately before integration, was crucial in avoiding cascading errors and allowed us to isolate problems more easily. For example, we verified camera compatibility using both OpenCV and NVIDIA’s native capture tool before beginning inference work, which saved time later on.

Despite the successes, we encountered several challenges during the setup and implementation stages. These included GPU compatibility issues, installation errors with PyTorch wheels tailored for the Jetson platform, and runtime problems caused by mismatched Python versions and CUDA dependencies. I was responsible for resolving these installation errors, which involved identifying the correct versions of PyTorch and torchvision compatible with our Jetson Orin Nano’s architecture and CUDA configuration. I was also responsible for reinstalling the correct version of OpenCV that had GPU support, allowing us to take advantage of CUDA-accelerated image processing tasks. I also developed and tested the detection code to explicitly force GPU execution by setting the correct device flags and verifying performance using torch.cuda.is_available() and jtop. Furthermore, I addressed issues related to camera indexing, ensuring that our detection script interfaced with the correct video input stream. This hands-on troubleshooting process significantly enhanced my problem-solving skills, particularly in diagnosing and resolving complex hardware-software integration issues on embedded Linux systems.
# Learning Plan
During this project, I identified several knowledge gaps, particularly in deploying machine learning models on embedded hardware. Although I was comfortable with Python and basic AI workflows, I had limited experience working with CUDA acceleration on ARM-based systems and resolving compatibility issues between PyTorch, OpenCV, and Jetson-specific dependencies. Additionally, I realized that my understanding of GPU memory management and profiling tools was surface-level, especially when it came to interpreting performance metrics and optimizing inference latency.

To scale this solution for larger or industrial applications, I would need deeper expertise in model optimization using TensorRT and ONNX, as well as a stronger grasp of real-time operating systems, system-level resource constraints, and embedded Linux development. Skills in advanced GPU programming and power-efficiency optimization would also be critical for ensuring long-term, stable deployment in edge environments.

To improve my skills, I plan to focus on better understanding how GPU acceleration works, especially in the context of CUDA and embedded systems. I also want to get more comfortable working with model optimization tools like TensorRT and ONNX, since those were areas I found challenging during this project. Additionally, I’d like to build more confidence in debugging hardware-software compatibility issues, particularly on Linux-based systems like Jetson. These improvements will help me be better prepared for future projects that involve deploying AI on edge devices or working with real-time systems.
