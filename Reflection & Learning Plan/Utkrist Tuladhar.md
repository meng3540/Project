# Reflection
This experience improved my skills in model deployment, GPU profiling, and troubleshooting compatibility issues across frameworks. It also showed how parallel computing on embedded devices can enable real-time AI for applications like robotics and smart surveillance.
This project has taught the deployment of real-time object detection on an embedded GPU device (Jetson Nano). I learned to use tools like OpenCV with CUDA, YOLO pre-trained models, and ensorRT for acceleration. I improved my skills in GPU profiling, parallel programming, and AI model deployment. The hands-on experience showed me how embedded AI is applied in real-world systems like robotics and autonomous vehicles.
# Learning Plan
While working on this project, I identified the need to improve in the following areas:
•	Model conversion workflows (PyTorch → ONNX → TensorRT)
•	Performance tuning and profiling on embedded GPUs
•	Efficient camera data processing for real-time inference
To address these gaps, I plan to:
•	Complete NVIDIA’s Deep Learning Institute courses on TensorRT and Jetson optimization
•	Experiment with deploying different PyTorch models on edge devices
•	Use tools like Nsight Systems for in-depth performance analysis
These steps will help me become more confident in deploying optimized AI solutions on embedded systems.


